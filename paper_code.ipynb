{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fc9b5cc",
   "metadata": {},
   "source": [
    "1. Read the \"candidate_points.shp\" or \"sampling_points.shp\" shapefile to generate the buffer and the range of each image is determined based on the buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3244614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import float64\n",
    "def generating_buffer(points,out_path):\n",
    "    point = gpd.read_file(points)\n",
    "\n",
    "    point['oid'] = list(range(len(point)))\n",
    "    point[\"x\"] = point.centroid.map(lambda p: p.x)\n",
    "    point['y'] = point.centroid.map(lambda p:p.y)\n",
    "    x_mid = point['x'].tolist()\n",
    "    y_mid = point['y'].tolist()\n",
    "\n",
    "    # The size of the image is 200 x 200, so add 10.0 to x and y to create an array\n",
    "    buffer_size = 10.0\n",
    "    top_left_x = list(map(lambda x: x - buffer_size,x_mid))\n",
    "    top_left_y = list(map(lambda y: y + buffer_size,y_mid))\n",
    "    top_left_xy = list(zip(top_left_x,top_left_y))\n",
    "    top_right_x = list(map(lambda x: x + buffer_size,x_mid))\n",
    "    top_right_y = list(map(lambda y: y + buffer_size,y_mid))\n",
    "    top_right_xy = list(zip(top_right_x,top_right_y))\n",
    "    bottom_right_x = list(map(lambda x: x + buffer_size,x_mid))\n",
    "    bottom_right_y = list(map(lambda y: y - buffer_size,y_mid))\n",
    "    bottom_right_xy = list(zip(bottom_right_x,bottom_right_y))\n",
    "\n",
    "    bottom_left_x = list(map(lambda x: x - buffer_size,x_mid))\n",
    "    bottom_left_y = list(map(lambda y: y - buffer_size,y_mid))\n",
    "    bottom_left_xy = list(zip(bottom_left_x,bottom_left_y))\n",
    "    my_data_copy = point\n",
    "    for i in range(len(my_data_copy)):\n",
    "        point_list = [top_left_xy[i],top_right_xy[i],bottom_right_xy[i],bottom_left_xy[i]]\n",
    "        my_data_copy['geometry'][i] = Polygon(point_list)\n",
    "\n",
    "    my_data_copy.to_file(out_path)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    points = '/path/XXX'\n",
    "    out_path = '/path/XXX'\n",
    "    generating_buffer(points,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10581738",
   "metadata": {},
   "source": [
    "2. Training data preparation. 70% of the random 10000 sampled data was used as the training set, including 3390 paved and 3610 unpaved. (It can be operated in ArcGIS. The result has been included in the file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e86e10",
   "metadata": {},
   "source": [
    "3. Model training. Based on our sample points, Qgis was used for online training using Google satellite mapping service. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b56e4f",
   "metadata": {},
   "source": [
    "3. In order to run this code in Qgis, you need to install the relevant packages in Qgis's python environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6533a",
   "metadata": {},
   "source": [
    "3. This is an example using the vgg16 net, similar as other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa314a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import geopandas as gpd\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms \n",
    "import time\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "\n",
    "def training_model(sampling_path,out_dir):\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomAffine(degrees=15,scale=(0.8,1.5)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    learning_rate = 0.0001\n",
    "    ex_batch_size = 64\n",
    "    all_epoch = 50\n",
    "\n",
    "    data = gpd.read_file(sampling_path)\n",
    "\n",
    "    with TemporaryDirectory() as dirname:\n",
    "        #print('dirname is:', dirname)\n",
    "        os.makedirs(dirname+\"/paved\")\n",
    "        os.makedirs(dirname+\"/unpaved\")\n",
    "        \n",
    "        for i in range(len(data)):\n",
    "            pid = data['oid_1'][i]\n",
    "            label = data['gt'][i]\n",
    "            xx, yy = data['geometry'][i].exterior.coords.xy\n",
    "            extent_0 = np.unique(np.array(xx))[0]+0.1 \n",
    "            extent_1 = np.unique(np.array(xx))[1]-0.2  \n",
    "            extent_2 = np.unique(np.array(yy))[0]+0.1  \n",
    "            extent_3 = np.unique(np.array(yy))[1]-0.2  \n",
    "            extent = str(extent_0) + ',' + str(extent_1) + ',' +  str(extent_2) + ',' + str(extent_3) + ' [EPSG:3857]'\n",
    "            if label == 0:\n",
    "                temp_path = dirname +'/paved/'+ str(pid) + '.tif'           \n",
    "            if label == 1:\n",
    "                temp_path = dirname +'/unpaved/'+ str(pid) + '.tif'\n",
    "\n",
    "            if os.path.exists(temp_path):\n",
    "                pass\n",
    "            else:\n",
    "                processing.run(\"native:rasterize\", {'EXTENT':extent,'EXTENT_BUFFER':0,'TILE_SIZE':200,'MAP_UNITS_PER_PIXEL':0.1,'MAKE_BACKGROUND_TRANSPARENT':False,'MAP_THEME':None,'LAYERS':['type=xyz&zmin=0&zmax=20&url=https://mt1.google.com/vt/lyrs%3Ds%26x%3D{x}%26y%3D{y}%26z%3D{z}'],'OUTPUT':temp_path})\n",
    "\n",
    "        trainset = torchvision.datasets.ImageFolder(root=dirname,transform = train_transform)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset,batch_size = ex_batch_size,shuffle = True,num_workers = 0)\n",
    "    \n",
    "        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        model = models.vgg16(pretrained = True)\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir)\n",
    "\n",
    "        model.classifier._modules['6'] = nn.Linear(4096,2)\n",
    "        model.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    \n",
    "        since = time.time()\n",
    "        for epoch in range(all_epoch):\n",
    "            # initialize \n",
    "            train_loss = 0.0\n",
    "            train_accuracy = 0.0\n",
    "            run_accuracy = 0.0\n",
    "            run_loss =0.0\n",
    "            total = 0.0\n",
    "            model.train()\n",
    "            for i,data in enumerate(train_loader,0):\n",
    "                images, labels = data\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)  \n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outs = model(images)\n",
    "                loss = criterion(outs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total += labels.size(0)\n",
    "                run_loss += loss.item()\n",
    "                _,prediction = torch.max(outs,1)\n",
    "                run_accuracy += (prediction == labels).sum().item()\n",
    "                if i % 20 == 19:\n",
    "                    print('epoch {},iter {},train accuracy: {:.4f}%   loss:  {:.4f}'.format(epoch, i+1, 100*run_accuracy/(labels.size(0)*20), run_loss/20))\n",
    "                    train_accuracy += run_accuracy\n",
    "                    train_loss += run_loss\n",
    "                    run_accuracy, run_loss = 0., 0.\n",
    "                \n",
    "            time_elapsed = time.time() - since\n",
    "            print('Epoch Finished inï¼š {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed%60))\n",
    "            if(epoch == 49):\n",
    "                epoch_name = out_dir + 'epoch_50.pth'\n",
    "                torch.save(model.state_dict(), epoch_name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    sampling_path = '.../path/XXX' #generated buffer file from sampling_points.shp  ---absolute path\n",
    "    out_dir = '.../path/XXX' #result weight file path\n",
    "    training_model(sampling_path,out_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d721cdcc",
   "metadata": {},
   "source": [
    "4. Model Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb10975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import processing\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from shapely.geometry.point import Point\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "def prediction(weight_path,input_dir,out_path):\n",
    "\n",
    "    data = gpd.read_file(input_dir)\n",
    "\n",
    "    transform= transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    model = models.vgg16(pretrained = False,num_classes=2)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(torch.load(weight_path))\n",
    "    \n",
    "    pred_list = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        with TemporaryDirectory() as dirname:\n",
    "            #print('dirname is:', dirname)\n",
    "            pid = data['oid_1'][i]\n",
    "            xx, yy = data['geometry'][i].exterior.coords.xy\n",
    "            extent_0 = np.unique(np.array(xx))[0]+0.1 \n",
    "            extent_1 = np.unique(np.array(xx))[1]-0.2  \n",
    "            extent_2 = np.unique(np.array(yy))[0]+0.1  \n",
    "            extent_3 = np.unique(np.array(yy))[1]-0.2  \n",
    "            extent = str(extent_0) + ',' + str(extent_1) + ',' +  str(extent_2) + ',' + str(extent_3) + ' [EPSG:3857]'\n",
    "            temp_path = dirname +'/'+ str(pid) + '.tif'\n",
    "            processing.run(\"native:rasterize\", {'EXTENT':extent,'EXTENT_BUFFER':0,'TILE_SIZE':200,'MAP_UNITS_PER_PIXEL':0.1,'MAKE_BACKGROUND_TRANSPARENT':False,'MAP_THEME':None,'LAYERS':['type=xyz&zmin=0&zmax=20&url=https://mt1.google.com/vt/lyrs%3Ds%26x%3D{x}%26y%3D{y}%26z%3D{z}'],'OUTPUT':temp_path})\n",
    "            #print(temp_path)\n",
    "            img = Image.open(temp_path)\n",
    "            #print(img)\n",
    "            img = transform(img)\n",
    "            img = img.unsqueeze(0)\n",
    "            img = img.to(device)\n",
    "            out = model(img)\n",
    "            out =  F.softmax(out,dim=1).cpu()\n",
    "            _, predicted = torch.max(out, 1)\n",
    "            pred = predicted.item()\n",
    "            #print(pred)\n",
    "            pred_list.append(pred)\n",
    "            temp_path = None\n",
    "\n",
    "    data['predict'] = pred_list\n",
    "    data.to_file(out_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    weight_path = '.../vgg16_7000.pth'  #Has been included in the file  ---absolute path\n",
    "    input_dir = '.../path/XXX' #generated buffer file from candidate_points.shp  ---absolute path\n",
    "    out_path = '.../path/XXX' #result ---absolute path\n",
    "    \n",
    "    prediction(weight_path,input_dir,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546cae4c",
   "metadata": {},
   "source": [
    "5. Model adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a39f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "def majority_vote(series):\n",
    "    counts = Counter(series)\n",
    "    most_common = counts.most_common(2)\n",
    "    if len(most_common) == 1 or most_common[0][1] > most_common[1][1]:\n",
    "        return most_common[0][0]\n",
    "    return None\n",
    "def modification(input_path,out_path):\n",
    "# Groups by original_id and then vote on the predict for each group\n",
    "    data = gpd.read_file(input_path)\n",
    "    data['predict_copy'] = data.groupby('ORIG_FID')['predict'].transform(majority_vote)\n",
    "    data.to_file(out_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    input_path = '/path/XXX' # the out_path of step 4\n",
    "    out_path = '/path/XXX'\n",
    "    modification(input_path,out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a6b5a",
   "metadata": {},
   "source": [
    "6. According to rule 2, count the unclassified roads, re-generat the candidate points in ArcGIS following rule 2, and then predict and vote again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e222ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = gpd.read_file('/path/XXX') #the out_path of step 5\n",
    "select_data = data[data['predict_copy'] == None]\n",
    "select_data.to_file('/path/XXX')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f94bd4",
   "metadata": {},
   "source": [
    "Repeat the above steps for full data generating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd88c65",
   "metadata": {},
   "source": [
    "Re-match the result point file with OSM road data in arcGIS to obtain the final result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
